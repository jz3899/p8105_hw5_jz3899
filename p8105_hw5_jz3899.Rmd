---
title: "p8105_hw5_jz3899"
author: "Jicong Zhang"
date: "2025-11-13"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rvest)
knitr::opts_chunk$set(
  fig.width = 9,
  fig.asp = .6,
  out.width = "100%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1
```{r}
shared_birthday = function(group_size){
  birthdays = sample(1:365, size = group_size, replace = TRUE)
  return(length(unique(birthdays)) < group_size)
}

n_sim = 10000
group_sizes = 2:50
prob_shared = numeric(length(group_sizes))
set.seed(1)

for(i in seq_along(group_sizes)){
  group = group_sizes[i]
  results = replicate(n_sim, shared_birthday(group))
  prob_shared[i] = mean(results)
}

plot(group_sizes, prob_shared,
     type = "l", lwd = 2,
     xlab = "Group Size",
     ylab = "Probability of Shared Birthday",
     main = "Birthday Problem Simulation (10,000 runs per group size)")
grid()
```

# Problem 2
```{r}
set.seed(1)
n = 30
sigma = 50
mu = 0:6
nsim = 5000
results = map_df(mu, function(mu_true){
  sims = replicate(nsim, {
    x = rnorm(n, mean = mu_true, sd=sigma)
    test = t.test(x,mu = 0)
    tibble(
      mu_hat = mean(x),
      pval=test$p.value,
      reject = test$p.value <0.05,
      mu_true = mu_true
    )
  },simplify = FALSE)
  bind_rows(sims)
})

power_df = results %>%
  group_by(mu_true) %>%
  summarize(power = mean(reject))

mu_hat_df = results %>%
  group_by(mu_true) %>%
  summarize(mean_mu = mean(mu_hat),
            mean_mu_reject = mean(mu_hat[reject]))
```

```{r}
ggplot(power_df, aes(x = mu_true, y = power)) +
  geom_line() +
  geom_point() +
  labs(title = "Power vs True Mean (Effect Size)",
       x = "True Mean (μ)",
       y = "Power (Probability of Rejecting H0)")
```

**Power is low when μ = 0 or close to 0. As μ increases, the probability of rejecting the false null increases sharply. So larger effect sizes increase statistical power.**

```{r}
ggplot(mu_hat_df, aes(x = mu_true)) +
  geom_line(aes(y = mean_mu), size = 1) +
  geom_point(aes(y = mean_mu), size = 2) +
  geom_line(aes(y = mean_mu_reject)) +
  geom_point(aes(y = mean_mu_reject), shape = 17, size = 2) +
  labs(title = "Average Sample Means",
       x = "True Mean (μ)",
       y = "Average Estimated Mean (μ̂)")
```

**The overall mean μhat closely matches the true μ.**

# Problem 3
```{r}
homi_df =
  read_csv("./homicide-data.csv", na = c("NA",".", "")) %>%
  janitor::clean_names()
homi_df
glimpse(homi_df)
```

**There are 52179 rows and 12 columns in this dataset. Some important variables are reported_date, victim_age, city and state.**

```{r}
city_df = homi_df %>%
  mutate(city_state = str_c(city, state, sep = ",")) %>%
  group_by(city_state) %>%
  summarize(
    total = n(),
    unsolved = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  )
city_df
```

```{r}
baltimore = city_df %>%
  filter(city_state == "Baltimore,MD")
bal_prop = prop.test(baltimore$unsolved, baltimore$total)
bal_tidy = broom::tidy(bal_prop)
bal_tidy %>%
  select(estimate, conf.low, conf.high) %>%
  knitr::kable(digits = 3)
bal_tidy

```

```{r}
homicides_props = city_df %>%
  mutate(
    test_results = map2(unsolved, total, ~ prop.test(.x, .y)),
    tidy_results = map(test_results, broom::tidy)
  ) %>%
  unnest(tidy_results) %>%
  select(city_state, estimate, conf.low, conf.high, total, unsolved)
homicides_props
```

```{r}
homicides_props %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Estimated Proportion Unsolved"
  )

```

